# PC Data Scraping, Cleaning, and Visualization

This repository contains a Jupyter Notebook, `scraping-cleaning-visualization.ipynb`, which demonstrates the process of scraping data about PCs from the Jumia website, cleaning the collected data, and visualizing the information using Python libraries, including seaborn.

## Notebook Contents

The notebook includes the following sections:

1. Data Scraping:
   - Utilizing **selenium** to gather data about PCs from the Jumia website.
   - Extracting relevant information such as PC type, price, and old price.

2. Data Cleaning:
   - Diagnosing and addressing potential problems in the scraped data, such as missing values or inconsistent formats.
   - Applying necessary cleaning and transformation steps to ensure data quality and usability.

3. Data Visualization:
   - Utilizing seaborn and other Python libraries to visualize the data, with a particular focus on the distribution of prices according to PC type and old price.
   - Generating visualizations that provide insights and facilitate understanding of the collected PC data.

## Requirements

To run the notebook successfully, you will need the following Python libraries:
- selenium
- pandas
- missingno
- time
- matplolib
- seaborn

